{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection using OpenCV\n",
    "\n",
    "OpenCV is an awesome, flexible, extensible platform to build Machine Learning models in the Computer Vision space. Here is a tutorial explaining how to build a haar cascade (Object Detection) from scratch and use it in your application. The cascade I am building here is to detect coca cola logos in pictures and videos. The demo of this cascade is here https://www.youtube.com/watch?v=erSePe_KtNU and https://www.youtube.com/watch?v=qQywEw6g9rI .\n",
    "\n",
    "The entire code and data set used for positive and negative samples are here https://github.com/ckarthic/objectdetectionopencv\n",
    "\n",
    "These are some awesome tutorials describing how to build cascades here. So please read them first to get the theory behind. \n",
    "1. https://docs.opencv.org/3.2.0/dc/d88/tutorial_traincascade.html\n",
    "2. https://docs.opencv.org/2.4/doc/user_guide/ug_traincascade.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare positive samples\n",
    "\n",
    "Positive samples have to be manually generated by using the Opencv_annotate tool. But, first we need to get a collection of pictures that have the object that we need to train the cascaded to detect. In our case it is the coke logo. Coke logos are usually seen in advertisements. So use google image search for 'coca cola advertisements' and download the positive samples one by one. Or even better download the 'Google Images download' python package here https://github.com/hardikvasa/google-images-download. This is an awesome package for creating datasets. It is a god's send for me actually. Here is how I used it to download pictures with coke logos\n",
    "\n",
    "`googleimagesdownload.exe -k \"coca cola\" -sk advertisements -f png -o Pos -s medium`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the object from positive samples\n",
    "\n",
    "Now that we have the positive samples. We need to extract the object (coke logo in our case) from the samples. It is the object that the cascasde will be trained to detect. The best way or (at least my way) to do it is use the opencv_annotate application to iterate through each of the sample and mark the rectagle region of the object to create an annotation file. My powershell script to run the app is below\n",
    "\n",
    "```\n",
    "$datafile = 'info/info_pos_round.data' \n",
    "$opencv_annotations = 'C:\\Users\\rithanya\\Documents\\Python\\opencv-master\\Build\\opencv\\build\\x64\\vc15\\bin\\opencv_annotation.exe'\n",
    "$folderpath = './Source'\n",
    "\n",
    "& $opencv_annotations --annotations=$datafile --images=$folderpath```\n",
    "\n",
    "Once we have the annotation file, Run the following python script to extract the objects (logo in our case) and resize them to the same size. It seems the smaller the size of the object the better it is interms of training time and accuracy. Also try to get objects from as many image image samples as possible. I extracted 58 logo images to train the cascasde in my project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractObject(datafile = \"info_nike_demo.data\", # annotation file\n",
    "                  pathtowrite = \"./Train/\"):\n",
    "\n",
    "    #open datafile\n",
    "    f = open(datafile)\n",
    "    content = f.read()\n",
    "    i = 1\n",
    "    for l in content.split('\\n'):\n",
    "        words = l.split()\n",
    "        if(len(words) >= 6): # coz sometimes the images have no region. \n",
    "            img_path = ' '.join(words[:-5]) # path the positive sample file\n",
    "            img_path = img_path.replace('\\\\','/') # replace back-slash if you are window user\n",
    "            img = cv2.imread(img_path,0) # read the read the sample using OpenCV\n",
    "            logo = [int(w) for w in words[-4:]] #extract the logo\n",
    "            x,y,w,h = logo\n",
    "            logograb = img[y:y+h, x:x+w]\n",
    "            # keep the size small to keep the training time short\n",
    "            img = cv2.resize(logograb, (60,20), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite(pathtowrite + str(i) + '.jpg', img)\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create .vec file from extracted objects\n",
    "\n",
    "The opencv_traincascade application that trains the cascade takes the positive images in the form of a .vec file. We can use the opencv_createsamples application to create the .vec file. But before that we need to build an another annotation file for the resized object (logo) samples. This is because the createsamples application takes this annotation file as an input to create the .vec file. Since the logo comprises the entirety of image files extracted in the step above the annotation file contents will look like like this\n",
    "\n",
    "```\n",
    "Source/logo_orig/1.jpg 1 0 0 60 20\n",
    "Source/logo_orig/10.jpg 1 0 0 60 20\n",
    "```\n",
    "\n",
    "This annotation file can be created quickly by the following python script\n",
    "\n",
    "```\n",
    "def create_infodata(imgfolder = 'Source/logo_orig'):\n",
    "    for img in os.listdir(imgfolder):\n",
    "        line = imgfolder + \"/\" + img + \" 1 0 0 60 20\\n\"\n",
    "        with open('info_pos_orig.data','a') as f:\n",
    "            f.write(line)\n",
    "```\n",
    "Once the annotation file is create, the following powershell command will create the .vec file from the positive samples\n",
    "\n",
    "```\n",
    "$opencv_createsamples = 'C:\\Users\\rithanya\\Documents\\Python\\opencv-master\\Build\\opencv\\build\\x64\\vc15\\bin\\opencv_createsamples.exe'\n",
    "& $opencv_createsamples -info info_pos_orig.data -num 58 -w 60 -h 20 -vec pos_orig.vec -show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Negative samples\n",
    "\n",
    "The accuracy of your cascade depends on the quantity and diversity of the negative samples. Good negative samples are those that \n",
    "are in the background of the image or video we are going to detect the object in. In our project, good negative files are advertisements  from another soft drink similar to coke. So I ran the following script to download 100 pepsi advertisements from google image search. One important thing to do here is preview these negative images and delete those who have coke logos in them. Negative images shouldn't have any positive objects by accident. \n",
    "\n",
    "`googleimagesdownload.exe -k \"pepsi\" -sk advertisements -f png -o Neg -s medium`\n",
    "\n",
    "From what I read, it seems the negative samples should be in the thousands. So I used the Scikit-Learn's PatchExtractor module to create about 6000 or so patches of size 100 x 100 to act as negative samples to train the cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "from skimage import data, transform\n",
    "\n",
    "def extract_patches(img, N, scale=1.0, patch_size=(100,100)):\n",
    "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
    "                               max_patches=N, random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale != 1:\n",
    "        patches = np.array([transform.resize(patch, patch_size)\n",
    "                            for patch in patches])\n",
    "    return patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code that creates 75 patches from every advertisement downloaded above, resizes them to size 100 x 100\n",
    "\n",
    "```\n",
    "images = []\n",
    "rootfolder = 'Neg'\n",
    "for imgfolder in os.listdir(rootfolder): #iterate thru each of the 5 celeb folders\n",
    "    if(imgfolder == 'pepsi advertisements'):\n",
    "        for filename in os.listdir(rootfolder + '/' + imgfolder):# iterate thru each image in a celeb folder\n",
    "            filename = rootfolder + '/' + imgfolder + '/' + filename # build the path to the image file\n",
    "            if(filename.endswith('.jpg')):\n",
    "                img = cv2.imread(filename)\n",
    "                if(img != None):\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    images.append(img)\n",
    "\n",
    "negative_patches = np.vstack([extract_patches(im, 75, scale)\n",
    "                             for im in images for scale in [1.0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bg.txt\n",
    "\n",
    "Now we need to create bg.txt file the lists all the negative samples one per line. The content of the bg.txt look like this\n",
    "\n",
    "```\n",
    "NegFromAds/Patches/1.jpg\n",
    "NegFromAds/Patches/2.jpg\n",
    "\n",
    "```\n",
    "\n",
    "It isn't trivial to build this bg.txt by hand for our thousands of negative samples. The following python script does the trick.\n",
    "\n",
    "```\n",
    "def create_bgtxt(imgfolder = 'Neg/Patches'):\n",
    "    for img in os.listdir(imgfolder):\n",
    "        line = imgfolder + \"/\" + img + \"\\n\"\n",
    "        with open('bg.txt','a') as f:\n",
    "            f.write(line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the cascade\n",
    "\n",
    "Now that we have both positive and negative samples, it is time to train the cascade using the following script. For 6500 negative samples of size 100 x 100 and 58 positive samples of size 60 x 20, the cascade trained for about 30 minutes in my laptop. \n",
    "\n",
    "```\n",
    "$opencv_traincascade = 'C:\\Users\\rithanya\\Documents\\Python\\opencv-master\\Build\\opencv\\build\\x64\\vc15\\bin\\opencv_traincascade.exe'\n",
    "& $opencv_traincascade -data cascade -vec Pos.vec -bg Negative.txt -numPos 11 -numNeg 12 -numStages 10 -w 20 -h 20\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the cascade\n",
    "Test the cascade using the following python script. It turns out that the parameters for the detectMultiScale is as important as the cascade itself to optimize the detection accuracy. To find the right balance between selectivity and sensitivity. Here is a very good explanation of the parameters of the detectMultiScale function https://stackoverflow.com/questions/20801015/recommended-values-for-opencv-detectmultiscale-parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cokelogo_cascade = \"C:/Users/rithanya/Documents/Python/Industrial_Safety/coke/cascade.xml\"\n",
    "cokecascade = cv2.CascadeClassifier(cokelogo_cascade)\n",
    "\n",
    "#utility function to apply different cascade function on the images at difference scaleFactor\n",
    "def detect(faceCascade, gray_,  scaleFactor_ = 1.1, minNeighbors = 5):\n",
    "    faces = faceCascade.detectMultiScale(gray_,\n",
    "                    scaleFactor= scaleFactor_,\n",
    "                    minNeighbors=5,\n",
    "                    minSize= (30,30), #(60, 20),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "    return faces\n",
    "\n",
    "def DetectAndShow(imgfolder = 'NegFromAds/coca cola advertisements/'):\n",
    "    cokelogo_cascade = \"./cascade4/cokelogoorigfullds.xml\"\n",
    "    cokecascade = cv2.CascadeClassifier(cokelogo_cascade)\n",
    "    for i in os.listdir(imgfolder):\n",
    "        filepath = imgfolder + i\n",
    "        img = cv2.imread(filepath)\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cokelogos = detect(cokecascade, gray, 1.25, 6)\n",
    "        for (x, y, w, h) in cokelogos:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.imshow('positive samples',img)\n",
    "        k = 0xFF & cv2.waitKey(0)\n",
    "        if k == 27:         # q to exit\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
